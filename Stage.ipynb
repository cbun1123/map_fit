{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/cbun1123/map_fit/blob/main/Stage.ipynb",
      "authorship_tag": "ABX9TyNd8dm4/6qm9c1cpjd19juN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbun1123/map_fit/blob/main/Stage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!rm -r /content/map_fit\n",
        "!git clone https://github.com/cbun1123/map_fit\n",
        "\n",
        "!unzip /content/map_fit/8bit/X_train_1.zip -d /content/map_fit/X_train\n",
        "!unzip /content/map_fit/8bit/X_train_2.zip -d /content/map_fit/X_train\n",
        "\n",
        "!unzip /content/map_fit/8bit/X_test_1.zip -d /content/map_fit/X_test\n",
        "\n",
        "!rm /content/map_fit/*.zip"
      ],
      "metadata": {
        "id": "0mtWihytt32k"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#!pip install cloud-tpu-client==0.10 torch==1.12.0 https://storage.googleapis.com/tpu-pytorch/wheels/cuda/112/torch_xla-1.12-cp37-cp37m-linux_x86_64.whl --force-reinstall\n",
        "#!pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master --upgrade\n",
        "!pip install pytorch-lightning\n",
        "!pip install tensorboardcolab\n",
        "!pip install torchmetrics\n",
        "%env PYTHONPATH=.:$PYTHONPATH"
      ],
      "metadata": {
        "id": "PyjF4ET6Ryta"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ow-HQUN3k9SA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e1c536b-6778-477d-ce94-4e235aa1f8c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Thu Aug 18 14:30:24 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "n = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import gc\n",
        "import natsort\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.onnx\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import torchmetrics\n",
        "from torchmetrics.functional import *\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm"
      ],
      "metadata": {
        "id": "Gj6-PAXEtQDT"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir='/content/lightning_logs'"
      ],
      "metadata": {
        "id": "863-WKKY3pU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Training data\n",
        "\n",
        "filenames = glob.glob(\"/content/map_fit/X_train/*.jpg\")\n",
        "filenames = natsort.natsorted(filenames)\n",
        "X_train = [cv2.imread(img,-1) for img in filenames] # cv2.imread(img)\n",
        "\n",
        "y_train = np.load('/content/map_fit/8bit/Y_train.npy')\n",
        "Z_train = np.load('/content/map_fit/8bit/Z_train.npy')\n",
        "print(f'Training set : {np.shape(X_train)}')\n",
        "\n",
        "## Testing data\n",
        "\n",
        "filenames = glob.glob(\"/content/map_fit/X_test/*.jpg\")\n",
        "filenames = natsort.natsorted(filenames)\n",
        "X_test = [cv2.imread(img,-1) for img in filenames]\n",
        "\n",
        "y_test = np.load('/content/map_fit/8bit/Y_test.npy')\n",
        "Z_test = np.load('/content/map_fit/8bit/Z_test.npy')\n",
        "print(f'Testing set : {np.shape(X_test)}')"
      ],
      "metadata": {
        "id": "WHAHiJg7vmyk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1902bc85-0ef6-4fec-a216-c52e4d24a356"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set : (5000, 224, 224)\n",
            "Testing set : (1000, 224, 224)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SIZE = 224\n",
        "\n",
        "# Define mask\n",
        "lin = np.linspace(-1,1,SIZE)\n",
        "[Xm,Ym] = np.meshgrid(lin,lin)\n",
        "idx = ((Xm**2+Ym**2)<1)\n",
        "idx = np.stack([idx,idx,idx], axis=0)\n",
        "idx_t = torch.from_numpy(idx)\n",
        "\n",
        "# Define datesets\n",
        "class imageDataset(Dataset):\n",
        "    def __init__(self,X,y,Z):\n",
        "        'Initialization'\n",
        "        self.X = np.array(X).astype(np.float32) # /(2**16)\n",
        "        self.y = np.array(y).astype(np.float32) # /(2**16)\n",
        "        self.Z = np.array(Z).astype(np.float32)\n",
        "        self.n_samples = self.X.shape[0]\n",
        "\n",
        "        lambdaMask = lambda T: torch.mul(T,idx_t)\n",
        "        mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
        "        lambdaMean = lambda T: T + torch.mul(mean-T.mean(dim=[1,2]).view(3,1,1),idx_t)\n",
        "        std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
        "        lambdaStd = lambda T: torch.mul(T,torch.div(std,T.std(dim=[1,2]).view(3,1,1)))\n",
        "        self.transfor = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambdaMask),\n",
        "            transforms.Lambda(lambdaMean),\n",
        "            transforms.Lambda(lambdaStd),\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        X = (self.X[index]/255)*(self.Z[index,1]-self.Z[index,0]) + self.Z[index,0]\n",
        "        X = self.transform(X)\n",
        "        X = torch.mul(X,idx_t)\n",
        "\n",
        "        y = self.y[index]\n",
        "        y = torch.from_numpy(y)\n",
        "        sample = X,y\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "    def getData(self):\n",
        "      # X = torch.stack([torch.mul(self.transform(self.X[i]),idx_t) for i in range(len(self.y))])\n",
        "      y = torch.from_numpy(self.y)\n",
        "      return y\n",
        "\n",
        "# Init datasets\n",
        "trainset = imageDataset(X_train,y_train,Z_train)\n",
        "testset = imageDataset(X_test,y_test,Z_test)\n",
        "\n",
        "# Garbage collection\n",
        "del X_train\n",
        "del y_train\n",
        "del X_test\n",
        "del y_test\n",
        "del filenames\n",
        "del Xm\n",
        "del Ym\n",
        "del lin\n",
        "del idx\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "YeaSHISWLPdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fab3f1d-2a5d-448a-9832-0e3bf2fe2366"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1504"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freezing weights:\n",
        "```\n",
        "for param in backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "self.net = backbone\n",
        "```\n",
        "\n",
        "Replacing last layer:\n",
        "```\n",
        "backbone.fc = nn.Linear(in_features=backbone.fc.in_features, out_features=2, bias=True)\n",
        "self.net = backbone\n",
        "```\n",
        "\n",
        "Adding new last layer:\n",
        "```\n",
        "added_layer = nn.Linear(in_features=backbone.fc.out_features, out_features=2, bias=True)\n",
        "self.net = nn.Sequential(backbone,nn.ReLU(inplace=True),added_layer)\n",
        "```"
      ],
      "metadata": {
        "id": "zasYanDzx5Xy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dropout testing\n",
        "~~~\n",
        "def append_dropout(model, rate):\n",
        "    for name, module in model.named_children():\n",
        "        if len(list(module.children())) > 0:\n",
        "            append_dropout(module,rate)\n",
        "        if isinstance(module, nn.ReLU):\n",
        "            module.register_forward_hook(lambda m, inp, out: F.dropout(out, p=rate, training=m.training))\n",
        "            setattr(model, name, new)\n",
        "~~~"
      ],
      "metadata": {
        "id": "xSF1B_WhGHHi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model\n",
        "model_name = \"shufflenet_v2_x1_0\" # shufflenet_v2_x1_0\n",
        "\n",
        "# hyperparameters\n",
        "BATCH_SIZE = 512 # TPU has very little memory, 64 max\n",
        "num_epochs = 5\n",
        "val_check_interval = 0.5\n",
        "learning_rate = 0.001\n",
        "betas = [0.9,0.999] # Gradient decay factor, Squared\n",
        "eps = 1e-6\n",
        "weight_decay = 1e-3 # L2 Regularization\n",
        "step_size = 10 # Learn rate drop period\n",
        "gamma = 0.8 # Learn rate drop factor\n",
        "rate = 0.0 # Dropout rate, 0 for none\n",
        "swa_lrs = 1e-3 # Stochastic weight averaging factor\n",
        "\n",
        "# Defining model\n",
        "class LitModel(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # init a pretrained resnet\n",
        "        #backbone = torchvision.models.shufflenet_v2_x1_0(pretrained=True)\n",
        "        backbone = torch.hub.load('pytorch/vision:v0.10.0', model_name, pretrained=True)\n",
        "        backbone.fc = nn.Linear(in_features=backbone.fc.in_features, out_features=2, bias=True)\n",
        "        self.net = backbone\n",
        "\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.lr = learning_rate\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        return DataLoader(dataset=trainset, batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        return DataLoader(dataset=testset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        return DataLoader(dataset=testset, batch_size=self.batch_size)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        return DataLoader(dataset=testset, batch_size=self.batch_size)\n",
        "\n",
        "    def forward(self,x):\n",
        "        return self.net(x)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        input, labels = batch\n",
        "        output = self.net(input)\n",
        "        loss = F.mse_loss(output,labels) # mean_squared_log_error(output,labels) # F.mse_loss(output,labels)\n",
        "\n",
        "        # Logging to TensorBoard by default\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        input, labels = batch\n",
        "        output = self.net(input)\n",
        "        loss = F.mse_loss(output,labels)\n",
        "\n",
        "        # Logging to TensorBoard by default\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        input, labels = batch\n",
        "        output = self.net(input)\n",
        "        loss = torch.std(labels-output, dim=0).mean()\n",
        "        self.log(\"test_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        input, labels = batch\n",
        "        return self.net(input)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        # optimizer = torch.optim.RMSprop(self.parameters(), lr=self.lr, alpha=0.86, eps=eps, weight_decay=weight_decay, momentum=0.9)\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, betas=betas, eps=eps, weight_decay=weight_decay)\n",
        "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=step_size,gamma=gamma)\n",
        "        return [optimizer], [lr_scheduler]"
      ],
      "metadata": {
        "id": "Vl6yhwY9coxM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# model init\n",
        "model = LitModel() #.load_from_checkpoint(\"/content/checkpoints/last.ckpt\")\n",
        "\n",
        "# logger\n",
        "logger = pl.loggers.TensorBoardLogger(save_dir=os.getcwd(), version=n, name=\"lightning_logs\")\n",
        "n += 1\n",
        "\n",
        "# callbacks\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=\"/content/checkpoints\",\n",
        "                                      save_last=True,\n",
        "                                      save_top_k=1,\n",
        "                                      monitor=\"val_loss\",\n",
        "                                      mode=\"min\",\n",
        "                                      filename=model_name+\"-{epoch:02d}-{val_loss:.5f}\"\n",
        "                                      )\n",
        "\n",
        "stagnate_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                               mode=\"min\",\n",
        "                                               check_finite=True,\n",
        "                                               patience=np.ceil(num_epochs/val_check_interval)\n",
        "                                               )\n",
        "swa_callback = pl.callbacks.StochasticWeightAveraging(swa_lrs=swa_lrs)\n",
        "\n",
        "# Defining trainer\n",
        "trainer = pl.Trainer(accelerator=\"gpu\",             # CPU, GPU or TPU\n",
        "                     val_check_interval=val_check_interval,\n",
        "                     auto_lr_find=False,            # True or False   \n",
        "                     auto_scale_batch_size=None,    # None or \"binsearch\"\n",
        "                     deterministic=False,           # True or False\n",
        "                     fast_dev_run=False,            # True or False or Epoch count\n",
        "                     logger=logger,                 # logger or False\n",
        "                     max_epochs=1000,               # -1 for Infinite\n",
        "                     precision=32,                  # Default 32\n",
        "                     profiler=None,                 # None, \"simple\" or \"advanced\"\n",
        "                     enable_checkpointing=True,     # True or False\n",
        "                     callbacks=[checkpoint_callback, stagnate_callback, swa_callback],\n",
        "                     gradient_clip_val=0.25,\n",
        "                     log_every_n_steps=1\n",
        "                     #, overfit_batches=1, detect_anomaly=True\n",
        "                     )                  \n",
        "\n",
        "# Autotune hyperparameters\n",
        "trainer.tune(model=model)\n",
        "\n",
        "# Training\n",
        "trainer.fit(model=model)"
      ],
      "metadata": {
        "id": "a2eqAEcNKafw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Loading best checkpoint and getting test loss\n",
        "t_loss = trainer.test()[0].get('test_loss')\n",
        "\n",
        "# Get test data\n",
        "y_test = testset.getData()\n",
        "y_pred = torch.vstack(trainer.predict())"
      ],
      "metadata": {
        "id": "JSB5gRIF_QTH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "print(torch.abs(torch.div(y_pred-y_test,y_test)).mean().item())\n",
        "print(torch.abs(torch.div(y_pred-y_test,y_pred)).mean().item())\n",
        "\n",
        "# Define RMS histogram binning\n",
        "nb = 20\n",
        "bins1 = np.arange(0, max(torch.max(y_test[:,0]), torch.max(y_pred[:,0])), 1/nb)\n",
        "bins2 = np.arange(0, max(torch.max(y_test[:,1]), torch.max(y_pred[:,1])), 1/(2*nb))\n",
        "\n",
        "# Plot RMS distributions\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(y_test[:,0], bins=bins1, color='white', edgecolor='black')\n",
        "plt.hist(y_pred[:,0], bins=bins1, color='blue', alpha=0.6)\n",
        "plt.title(\"Distribution RMS RdB\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(y_test[:,1], bins=bins2, color='white', edgecolor='black')\n",
        "plt.hist(y_pred[:,1], bins=bins2, color='blue', alpha=0.6)\n",
        "plt.title(\"Distribution RMS MFcirc\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Define error distributions\n",
        "D_rdb = y_pred[:,0]-y_test[:,0] #torch.div(y_pred[:,0]-y_test[:,0],y_pred[:,0])\n",
        "D_mfcirc = y_pred[:,1]-y_test[:,1] #torch.div(y_pred[:,1]-y_test[:,1],y_pred[:,1])\n",
        "\n",
        "# Define error histogram binning\n",
        "nb = 20\n",
        "bins3 = np.arange(-1, 1, 1/nb)\n",
        "bins4 = np.arange(-1, 1, 1/nb)\n",
        "\n",
        "# Plot error distributions\n",
        "plt.subplot(1,2,1)\n",
        "plt.hist(D_rdb, bins=bins3, color='blue', edgecolor='black')\n",
        "plt.title(\"Erreurs relatives RdB\")\n",
        "plt.subplot(1,2,2)\n",
        "plt.hist(D_mfcirc, bins=bins4, color='blue', edgecolor='black')\n",
        "plt.title(\"Erreurs relatives MFcirc\")\n",
        "plt.show()\n",
        "\n",
        "# Print error std\n",
        "std_rdb = torch.std(D_rdb).item()\n",
        "std_mfcirc = torch.std(D_mfcirc).item()\n",
        "print(f'Standard deviation of RdB errors : {std_rdb:.3f}')\n",
        "print(f'Standard deviation of MFcirc errors : {std_mfcirc:.3f}')"
      ],
      "metadata": {
        "id": "pFQ-UsQF80CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_img = cv2.imread(\"/content/map_fit/8bit/-137.319_158.003_37.932_20_30.jpg\",-1)\n",
        "Z = [-137.319,158.003]\n",
        "RMS = 37.932\n",
        "cv2_imshow(test_img)\n",
        "\n",
        "X = np.array(test_img).astype(np.float32)\n",
        "X = (X/255)*(Z[1]-Z[0])+Z[0]\n",
        "X = X/RMS\n",
        "\n",
        "lambdaMask = lambda T: torch.mul(T,idx_t)\n",
        "mean = torch.tensor([0.485, 0.456, 0.406]).view(3,1,1)\n",
        "lambdaMean = lambda T: T + torch.mul(mean-T.mean(dim=[1,2]).view(3,1,1),idx_t)\n",
        "std = torch.tensor([0.229, 0.224, 0.225]).view(3,1,1)\n",
        "lambdaStd = lambda T: torch.mul(T,torch.div(std,T.std(dim=[1,2]).view(3,1,1)))\n",
        "X = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambdaMask),\n",
        "            transforms.Lambda(lambdaMean),\n",
        "            transforms.Lambda(lambdaStd),\n",
        "        ])(X)\n",
        "\n",
        "X = X[None,:,:,:]\n",
        "\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y = model(X)\n",
        "\n",
        "print(f'Predicted RMS: {RMS*y[0,0].item():.3f}, {RMS*y[0,1].item():.3f}')"
      ],
      "metadata": {
        "id": "aBbcZe7prq22"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Errors on the following block are mostly fixed by restarting it"
      ],
      "metadata": {
        "id": "sS9sRpBKFURj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# save for inference\n",
        "filename = f'/content/{model_name}_{std_rdb:.3f}_{std_mfcirc:.3f}_inf.onnx' # drive/MyDrive/ \n",
        "\n",
        "# Input to the model\n",
        "x = torch.randn(1, 3, SIZE, SIZE, requires_grad=True)\n",
        "\n",
        "# Export the model\n",
        "model.to_onnx(filename, x, export_params=True)"
      ],
      "metadata": {
        "id": "v45W0Eh1nvRp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}