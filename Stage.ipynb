{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/cbun1123/map_fit/blob/main/Stage.ipynb",
      "authorship_tag": "ABX9TyPU2ix3opPpbbO8sVEaO/VK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbun1123/map_fit/blob/main/Stage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!rm -r /content/map_fit\n",
        "!git clone https://github.com/cbun1123/map_fit\n",
        "\n",
        "!unzip /content/map_fit/8bit/X_train_1.zip -d /content/map_fit/8bit/X_train\n",
        "!unzip /content/map_fit/8bit/X_train_2.zip -d /content/map_fit/8bit/X_train\n",
        "!unzip /content/map_fit/8bit/X_train_3.zip -d /content/map_fit/8bit/X_train\n",
        "\n",
        "!unzip /content/map_fit/8bit/X_test_1.zip -d /content/map_fit/8bit/X_test\n",
        "\n",
        "!rm /content/map_fit/*.zip"
      ],
      "metadata": {
        "id": "0mtWihytt32k"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#!pip install cloud-tpu-client==0.10 torch==1.12.0 https://storage.googleapis.com/tpu-pytorch/wheels/cuda/112/torch_xla-1.12-cp37-cp37m-linux_x86_64.whl --force-reinstall\n",
        "#!pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master --upgrade\n",
        "!pip install pytorch-lightning==1.5.10\n",
        "!pip install tensorboardcolab\n",
        "!pip install torchmetrics\n",
        "!pip install optuna==2.10.1\n",
        "%env PYTHONPATH=.:$PYTHONPATH"
      ],
      "metadata": {
        "id": "PyjF4ET6Ryta"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ow-HQUN3k9SA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3208c5b1-5152-4d66-e177-3f463469b686"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NVIDIA-SMI has failed because it couldn't communicate with the NVIDIA driver. Make sure that the latest NVIDIA driver is installed and running.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "n = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import gc\n",
        "import natsort\n",
        "import logging\n",
        "\n",
        "from IPython.utils import io\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.onnx\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import optuna\n",
        "\n",
        "import torchmetrics\n",
        "from torchmetrics.functional import *\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm"
      ],
      "metadata": {
        "id": "Gj6-PAXEtQDT",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir='/content/lightning_logs'"
      ],
      "metadata": {
        "id": "863-WKKY3pU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dataset\n",
        "#@markdown Loads datasets and creates training and testing dataloaders\n",
        "## Training data\n",
        "# Load training images\n",
        "filenames = glob.glob(\"/content/map_fit/8bit/X_train/*.jpg\")\n",
        "filenames = natsort.natsorted(filenames)\n",
        "train_num = 5000 #@param {type:\"slider\", min:0, max:10000, step:1}\n",
        "X_train = [cv2.imread(img,-1) for img in filenames[0:train_num]] # cv2.imread(img)\n",
        "\n",
        "# Load training labels\n",
        "y_train = np.load('/content/map_fit/8bit/Y_train.npy')[0:train_num]\n",
        "Z_train = np.load('/content/map_fit/8bit/Z_train.npy')[0:train_num]\n",
        "\n",
        "\n",
        "## Testing data\n",
        "# Load testing images\n",
        "filenames = glob.glob(\"/content/map_fit/8bit/X_test/*.jpg\")\n",
        "filenames = natsort.natsorted(filenames)\n",
        "test_num = 1000 #@param {type:\"slider\", min:0, max:2000, step:1}\n",
        "X_test = [cv2.imread(img,-1) for img in filenames[0:test_num]]\n",
        "\n",
        "# Load training labels\n",
        "y_test = np.load('/content/map_fit/8bit/Y_test.npy')[0:test_num]\n",
        "Z_test = np.load('/content/map_fit/8bit/Z_test.npy')[0:test_num]\n",
        "\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f'Training set : {np.shape(X_train)}')\n",
        "print(f'Testing set : {np.shape(X_test)}')\n",
        "\n",
        "\n",
        "SIZE = 224\n",
        "\n",
        "# Define circular mask for RGB tensor image\n",
        "lin = np.linspace(-1,1,SIZE)\n",
        "[Xm,Ym] = np.meshgrid(lin,lin)\n",
        "idx = ((Xm**2+Ym**2)<1)\n",
        "idx = np.stack([idx,idx,idx], axis=0)\n",
        "idx_t = torch.from_numpy(idx)\n",
        "\n",
        "# Define custom dataset class inheriting from torch.Dataset\n",
        "class imageDataset(Dataset):\n",
        "    def __init__(self,X,y,Z):\n",
        "        'Initialization'\n",
        "        # Load data\n",
        "        self.X = np.array(X).astype(np.float32)\n",
        "        self.y = np.array(y).astype(np.float32)\n",
        "        self.Z = np.array(Z).astype(np.float32)\n",
        "\n",
        "        # Define dataset size\n",
        "        self.n_samples = self.X.shape[0]\n",
        "\n",
        "        # Define target distribution\n",
        "        mean = torch.tensor([0.5, 0.5, 0.5]).view(3,1,1)\n",
        "        std = torch.tensor([0.5, 0.5, 0.5]).view(3,1,1)\n",
        "\n",
        "        # Define corrected distribution for masked image\n",
        "        fact = torch.div(SIZE**2,idx_t.sum(dim=[1,2])).view(3,1,1)\n",
        "        corr_mean = torch.mul(fact,mean)\n",
        "        corr_std = torch.sqrt(torch.mul(fact,torch.pow(std,2)) - torch.mul(torch.mul(fact,fact-1),torch.pow(mean,2)))\n",
        "\n",
        "        # Define transformations\n",
        "        lambdaMask = lambda T: torch.mul(T,idx_t)\n",
        "        lambdaNorm = lambda T: torch.div(T-T.mean(dim=[1,2]).view(3,1,1),T.std(dim=[1,2]).view(3,1,1))\n",
        "        lambdaScale = lambda T: torch.mul(T,corr_std) + corr_mean\n",
        "\n",
        "        # Define global transformation\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambdaMask),\n",
        "            transforms.Lambda(lambdaNorm),\n",
        "            transforms.Lambda(lambdaScale),\n",
        "            transforms.Lambda(lambdaMask),\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        X = self.X[index]\n",
        "\n",
        "        # Rescale sample to original values\n",
        "        #X = (X/255)*(self.Z[index,1]-self.Z[index,0]) + self.Z[index,0]\n",
        "\n",
        "        # Apply transforms\n",
        "        X = self.transform(X)\n",
        "\n",
        "        # Load and format labels\n",
        "        y = self.y[index]\n",
        "        y = torch.from_numpy(y)\n",
        "\n",
        "        # Package sample\n",
        "        sample = X,y\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        'Dataset length'\n",
        "        return self.n_samples\n",
        "\n",
        "    def getData(self):\n",
        "        'Returns all data labels'\n",
        "\n",
        "        # Load all images\n",
        "        #X = torch.stack([torch.mul(self.transform(self.X[i]),idx_t) for i in range(len(self.y))])\n",
        "\n",
        "        # Load all labels\n",
        "        y = torch.from_numpy(self.y)\n",
        "        return y\n",
        "\n",
        "# Initialize datasets\n",
        "trainset = imageDataset(X_train,y_train,Z_train)\n",
        "testset = imageDataset(X_test,y_test,Z_test)\n",
        "\n",
        "# Garbage collection\n",
        "del X_train\n",
        "del y_train\n",
        "del X_test\n",
        "del y_test\n",
        "del filenames\n",
        "del Xm\n",
        "del Ym\n",
        "del lin\n",
        "del idx\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "YeaSHISWLPdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fecc9f8e-b140-46a9-83a0-a4ef220be89c",
        "cellView": "form"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set : (5000, 224, 224)\n",
            "Testing set : (1000, 224, 224)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freezing weights:\n",
        "```\n",
        "for param in backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "self.net = backbone\n",
        "```\n",
        "\n",
        "Replacing last layer:\n",
        "```\n",
        "backbone.fc = nn.Linear(in_features=backbone.fc.in_features, out_features=3, bias=True)\n",
        "self.net = backbone\n",
        "```\n",
        "\n",
        "Adding new last layer:\n",
        "```\n",
        "added_layer = nn.Linear(in_features=backbone.fc.out_features, out_features=3, bias=True)\n",
        "self.net = nn.Sequential(backbone,nn.ReLU(inplace=True),added_layer)\n",
        "```"
      ],
      "metadata": {
        "id": "zasYanDzx5Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Defining model and hyperparameters\n",
        "# Define model\n",
        "model_name = \"squeezenet1_1\" #@param {type:\"string\"}\n",
        "\n",
        "# Define hyperparameters\n",
        "BATCH_SIZE = 64 #@param {type:\"integer\"} # TPU has very little memory, 64 max\n",
        "\n",
        "#learning_rate = 0.0015\n",
        "#weight_decay = 1e-6\n",
        "#dropout_rate = 0.5\n",
        "#swa_lrs = 1e-6\n",
        "\n",
        "betas = [0.9,0.999]\n",
        "eps = 1e-8\n",
        "\n",
        "#@markdown Learning rate scheduler period\n",
        "step_size = 5 #@param {type:\"integer\"}\n",
        "#@markdown Learning rate scheduler factor\n",
        "gamma = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "# Define pyTorch-Lightning model class inheriting from LightningModule class\n",
        "class LitModel(pl.LightningModule):\n",
        "    def __init__(self,trial):\n",
        "        'Initialize module'\n",
        "        # Inherit initialization from LightningModule class\n",
        "        super().__init__()\n",
        "        # Define internal hyperparameters for tuning\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.lr = trial.suggest_float('learning_rate', 1e-6, 1e-2, log=True)\n",
        "        self.wd = trial.suggest_float('weight_decay', 1e-8, 1e-2, log=True)\n",
        "        self.p = trial.suggest_float('dropout_rate', 0.1, 0.6, log=True)\n",
        "\n",
        "        # Initialize a pretrained network\n",
        "        backbone = torch.hub.load('pytorch/vision:v0.10.0', model_name, pretrained=True)\n",
        "        #backbone = torchvision.models.shufflenet_v2_x1_0(pretrained=True)\n",
        "\n",
        "        # Custom dropout rate (default 0.5)\n",
        "        backbone.classifier[0] = nn.Dropout(p=self.p, inplace=False)\n",
        "\n",
        "        # Add fully-connected last layer for 3 parameter regression\n",
        "        added_layer = nn.Linear(in_features=1000, out_features=3, bias=True)\n",
        "        self.net = nn.Sequential(backbone,added_layer)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        'Training optimizers definition'\n",
        "        # Backpropagation optimize\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, betas=betas, eps=eps, weight_decay=self.wd)\n",
        "        #optimizer = torch.optim.RMSprop(self.parameters(), lr=self.lr, alpha=0.86, eps=eps, weight_decay=self.wd, momentum=0.9)\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=step_size,gamma=gamma)\n",
        "        return [optimizer], [lr_scheduler]\n",
        "\n",
        "    def forward(self,x):\n",
        "        'Forward function'\n",
        "        return self.net(x)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        'Internal training dataloader'\n",
        "        return DataLoader(dataset=trainset, batch_size=self.batch_size)\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        'Internal validation dataloader'\n",
        "        return DataLoader(dataset=testset, batch_size=self.batch_size)\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        'Internal testing dataloader'\n",
        "        return DataLoader(dataset=testset, batch_size=self.batch_size)\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        'Internal prediction dataloader'\n",
        "        return DataLoader(dataset=testset, batch_size=self.batch_size)\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        'Training loop step'\n",
        "        # Get data from batch\n",
        "        input, labels = batch\n",
        "        # Compute predictions\n",
        "        output = self.net(input)\n",
        "        # Compute loss\n",
        "        loss = F.mse_loss(output,labels) # mean_squared_log_error(output,labels) # F.mse_loss(output,labels)\n",
        "        # Logging to TensorBoard\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        'Validation loop step'\n",
        "        # Get data from batch\n",
        "        input, labels = batch\n",
        "        # Compute predictions\n",
        "        output = self.net(input)\n",
        "        # Compute loss\n",
        "        loss = F.mse_loss(output,labels)\n",
        "        # Logging to TensorBoard\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        'Testing loop step'\n",
        "        # Get data from batch\n",
        "        input, labels = batch\n",
        "        # Compute predictions\n",
        "        output = self.net(input)\n",
        "        # Compute loss\n",
        "        loss = torch.std(labels-output, dim=0).mean()\n",
        "        # Logging to TensorBoard\n",
        "        self.log(\"test_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        'Prediction loop step'\n",
        "        # Get data from batch\n",
        "        input, labels = batch\n",
        "        # Compute predictions\n",
        "        return self.net(input)"
      ],
      "metadata": {
        "id": "Vl6yhwY9coxM"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Optuna config\n",
        "max_epochs = 10 #@param {type:\"integer\"}\n",
        "#@markdown Patience\n",
        "num_epochs = 2 #@param {type:\"integer\"}\n",
        "val_check_interval = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "def objective(trial):\n",
        "    logger = pl.loggers.TensorBoardLogger(save_dir=os.getcwd(),version=trial.number ,name=\"optuna\")\n",
        "\n",
        "    checkpoint_callback = pl.callbacks.ModelCheckpoint(\n",
        "        dirpath=os.path.join(\"/content/optuna\", \"trial_{}\".format(trial.number)),\n",
        "        monitor=\"val_loss\",\n",
        "        save_top_k=1,\n",
        "        save_last=False)\n",
        "    pruning_callback = optuna.integration.PyTorchLightningPruningCallback(trial, monitor=\"val_loss\")\n",
        "    stagnate_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                               mode=\"min\",\n",
        "                                               check_finite=True,\n",
        "                                               patience=np.ceil(num_epochs/val_check_interval)\n",
        "                                               )\n",
        "    swa_callback = pl.callbacks.StochasticWeightAveraging(swa_lrs=trial.suggest_float('swa_lrs', 1e-7, 1e-2, log=True))\n",
        "\n",
        "    trainer = pl.Trainer(\n",
        "        accelerator=\"gpu\",             # CPU, GPU or TPU\n",
        "        val_check_interval=val_check_interval,\n",
        "        auto_scale_batch_size=None,    # None or \"binsearch\"\n",
        "        deterministic=False,           # True or False\n",
        "        fast_dev_run=False,            # True or False or Epoch count\n",
        "        logger=logger,                 # logger or False\n",
        "        max_epochs=max_epochs,         # -1 for Infinite\n",
        "        precision=32,                  # Default 32\n",
        "        profiler=None,                 # None, \"simple\" or \"advanced\"\n",
        "        enable_checkpointing=True,     # True or False\n",
        "        callbacks=[checkpoint_callback, pruning_callback, stagnate_callback, swa_callback],\n",
        "        gradient_clip_val=0.25,\n",
        "        log_every_n_steps=1,\n",
        "        #, detect_anomaly=True #, overfit_batches=1\n",
        "        )  \n",
        "\n",
        "    model = LitModel(trial)\n",
        "\n",
        "    trainer.fit(model=model)\n",
        "    t_loss = trainer.test()[0].get('test_loss')\n",
        "\n",
        "    return t_loss"
      ],
      "metadata": {
        "id": "UXwNpdY8t6e6"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Optuna config\n",
        "n_trials = 100 #@param {type:\"integer\"}\n",
        "\n",
        "pruner = optuna.pruners.MedianPruner()\n",
        "study = optuna.create_study(pruner=pruner)\n",
        "\n",
        "study.optimize(objective, n_trials=n_trials)\n",
        "best_params = study.best_params"
      ],
      "metadata": {
        "id": "Dye8BmrJ0s-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Training\n",
        "# Garbage collection\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Model initialization, possibly by checkpoint\n",
        "#@markdown Leave empty if no checkpoint\n",
        "ckpt_name = \"\" #@param {type:\"string\"}\n",
        "if ckpt_name == \"\":\n",
        "    model = LitModel()\n",
        "else:\n",
        "    model = LitModel().load_from_checkpoint(\"/content/checkpoints/\" + ckpt_name + \".ckpt\")\n",
        "\n",
        "\n",
        "# Define TensorBoard logger\n",
        "logger = pl.loggers.TensorBoardLogger(save_dir=os.getcwd(), version=n, name=\"lightning_logs\")\n",
        "n += 1\n",
        "\n",
        "# Define training callbacks\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=\"/content/checkpoints\",\n",
        "                                      save_last=True,\n",
        "                                      save_top_k=1,\n",
        "                                      monitor=\"val_loss\",\n",
        "                                      mode=\"min\",\n",
        "                                      filename=model_name+\"-{epoch:02d}-{val_loss:.5f}\"\n",
        "                                      )\n",
        "stagnate_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                               mode=\"min\",\n",
        "                                               check_finite=True,\n",
        "                                               patience=np.ceil(num_epochs/val_check_interval)\n",
        "                                               )\n",
        "swa_callback = pl.callbacks.StochasticWeightAveraging(swa_lrs=swa_lrs)\n",
        "\n",
        "# Defining trainer\n",
        "trainer = pl.Trainer(accelerator=\"gpu\",             # CPU, GPU or TPU\n",
        "                     val_check_interval=val_check_interval,\n",
        "                     auto_lr_find=False,            # True or False   \n",
        "                     auto_scale_batch_size=None,    # None or \"binsearch\"\n",
        "                     deterministic=False,           # True or False\n",
        "                     fast_dev_run=False,            # True or False or Epoch count\n",
        "                     logger=logger,                 # logger or False\n",
        "                     max_epochs=1000,               # -1 for Infinite\n",
        "                     precision=32,                  # Default 32\n",
        "                     profiler=None,                 # None, \"simple\" or \"advanced\"\n",
        "                     enable_checkpointing=True,     # True or False\n",
        "                     callbacks=[checkpoint_callback, stagnate_callback, swa_callback],\n",
        "                     gradient_clip_val=0.25,\n",
        "                     log_every_n_steps=1\n",
        "                     #, detect_anomaly=True #, overfit_batches=1\n",
        "                     )                  \n",
        "\n",
        "# Autotune hyperparameters\n",
        "trainer.tune(model=model)\n",
        "\n",
        "# Training\n",
        "trainer.fit(model=model)"
      ],
      "metadata": {
        "id": "a2eqAEcNKafw",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate test set\n",
        "# Garbage collection\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Load best checkpoint and get testing loss\n",
        "#t_loss = trainer.test()[0].get('test_loss')\n",
        "\n",
        "# Get test labels\n",
        "y_test = testset.getData()\n",
        "\n",
        "# Load best checkpoint and get test predictions\n",
        "y_pred = torch.vstack(trainer.predict())"
      ],
      "metadata": {
        "id": "fGt8UkbtXCI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Response distribution\n",
        "# Garbage collection\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Print mean relative errors\n",
        "#print(torch.abs(torch.div(y_pred-y_test,y_test)).mean().item())\n",
        "##print(torch.abs(torch.div(y_pred-y_test,y_pred)).mean().item())\n",
        "\n",
        "# Define RMS histogram binning\n",
        "nb = 20\n",
        "bins1 = np.arange(0, max(torch.max(y_test[:,0]), torch.max(y_pred[:,0])), 1/(2*nb))\n",
        "bins2 = np.arange(0, max(torch.max(y_test[:,1]), torch.max(y_pred[:,1])), 1/(nb/2))\n",
        "bins3 = np.arange(0, max(torch.max(y_test[:,2]), torch.max(y_pred[:,2])), 1/(2*nb))\n",
        "\n",
        "# Plot RMS distributions\n",
        "plt.subplot(1,3,1)\n",
        "plt.hist(y_test[:,0], bins=bins1, color='white', edgecolor='black')\n",
        "plt.hist(y_pred[:,0], bins=bins1, color='blue', alpha=0.6)\n",
        "plt.title(\"Dist RMS MHF\")\n",
        "plt.subplot(1,3,2)\n",
        "plt.hist(y_test[:,1], bins=bins2, color='white', edgecolor='black')\n",
        "plt.hist(y_pred[:,1], bins=bins2, color='blue', alpha=0.6)\n",
        "plt.title(\"Dist RMS BdR\")\n",
        "plt.subplot(1,3,3)\n",
        "plt.hist(y_test[:,2], bins=bins3, color='white', edgecolor='black')\n",
        "plt.hist(y_pred[:,2], bins=bins3, color='blue', alpha=0.6)\n",
        "plt.title(\"Dist RMS MFcirc\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Define error distributions\n",
        "D_mhf = y_pred[:,0]-y_test[:,0] #torch.div(y_pred[:,0]-y_test[:,0],y_pred[:,0])\n",
        "D_bdr = y_pred[:,1]-y_test[:,1] #torch.div(y_pred[:,1]-y_test[:,1],y_pred[:,1])\n",
        "D_mfcirc = y_pred[:,2]-y_test[:,2] #torch.div(y_pred[:,2]-y_test[:,2],y_pred[:,2])\n",
        "\n",
        "# Define error histogram binning\n",
        "nb = 20\n",
        "bins4 = np.arange(-1, 1, 1/nb)\n",
        "bins5 = np.arange(-1, 1, 1/nb)\n",
        "bins6 = np.arange(-1, 1, 1/nb)\n",
        "\n",
        "# Plot error distributions\n",
        "plt.subplot(1,3,1)\n",
        "plt.hist(D_mhf, bins=bins4, color='blue', edgecolor='black')\n",
        "plt.title(\"Erreurs relatives MHF\")\n",
        "plt.subplot(1,3,2)\n",
        "plt.hist(D_bdr, bins=bins5, color='blue', edgecolor='black')\n",
        "plt.title(\"Erreurs relatives BdR\")\n",
        "plt.subplot(1,3,3)\n",
        "plt.hist(D_mfcirc, bins=bins6, color='blue', edgecolor='black')\n",
        "plt.title(\"Erreurs relatives MFcirc\")\n",
        "plt.show()\n",
        "\n",
        "# Print error std\n",
        "std_mhf = torch.std(D_mhf).item()\n",
        "std_bdr = torch.std(D_bdr).item()\n",
        "std_mfcirc = torch.std(D_mfcirc).item()\n",
        "print(f'Standard deviation of MHF errors :    {std_mhf:.3f}')\n",
        "print(f'Standard deviation of BdR errors :    {std_bdr:.3f}')\n",
        "print(f'Standard deviation of MFcirc errors : {std_mfcirc:.3f}')"
      ],
      "metadata": {
        "id": "pFQ-UsQF80CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Single example\n",
        "# Load image and define parameters\n",
        "test_img = cv2.imread(\"/content/map_fit/8bit/-137.319_158.003_37.932_20_30.jpg\",-1)\n",
        "Z = [-137.319,158.003]\n",
        "RMS = 37.932\n",
        "E_RMS = [10,20,30]\n",
        "\n",
        "# Show test image\n",
        "cv2_imshow(test_img)\n",
        "\n",
        "# Normalize image\n",
        "X = np.array(test_img).astype(np.float32)\n",
        "X = (X/255)*(Z[1]-Z[0])+Z[0]\n",
        "X = X/RMS\n",
        "\n",
        "# Define target distribution\n",
        "mean = torch.tensor([0.5, 0.5, 0.5]).view(3,1,1)\n",
        "std = torch.tensor([0.5, 0.5, 0.5]).view(3,1,1)\n",
        "\n",
        "# Define corrected distribution for masked image\n",
        "fact = torch.div(SIZE**2,idx_t.sum(dim=[1,2])).view(3,1,1)\n",
        "corr_mean = torch.mul(fact,mean)\n",
        "corr_std = torch.sqrt(torch.mul(fact,torch.pow(std,2)) - torch.mul(torch.mul(fact,fact-1),torch.pow(mean,2)))\n",
        "\n",
        "# Define transformations\n",
        "lambdaMask = lambda T: torch.mul(T,idx_t)\n",
        "lambdaNorm = lambda T: torch.div(T-T.mean(dim=[1,2]).view(3,1,1),T.std(dim=[1,2]).view(3,1,1))\n",
        "lambdaScale = lambda T: torch.mul(T,corr_std) + corr_mean\n",
        "\n",
        "# Compute transformed image\n",
        "X = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambdaMask),\n",
        "            transforms.Lambda(lambdaNorm),\n",
        "            transforms.Lambda(lambdaScale),\n",
        "            transforms.Lambda(lambdaMask),\n",
        "            ])(X)\n",
        "\n",
        "# Add dummy batch dimension\n",
        "X = X[None,:,:,:]\n",
        "\n",
        "# Compute prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y = model(X)\n",
        "\n",
        "# Print results\n",
        "print(f' Expected RMS:    {E_RMS[0]:.3f},    {E_RMS[1]:.3f},    {E_RMS[2]:.3f}')\n",
        "print(f'Predicted RMS:    {RMS*y[0,0].item():.3f},    {RMS*y[0,1].item():.3f},    {RMS*y[0,2].item():.3f}')\n",
        "print(f' Error at std:  +-{std_mhf*RMS:.3f},  +-{std_bdr*RMS:.3f},  +-{std_mfcirc*RMS:.3f}')"
      ],
      "metadata": {
        "id": "aBbcZe7prq22",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Export to .onnx\n",
        "#@markdown Errors on this block are mostly fixed by restarting it\n",
        "# Target filename\n",
        "filename = f'C:/Users/maele/Desktop/map_fit-main/Export/{model_name}_{std_mhf:.3f}_{std_bdr:.3f}_{std_mfcirc:.3f}.onnx' # drive/MyDrive/ \n",
        "\n",
        "# Example input\n",
        "x = torch.randn(1, 3, SIZE, SIZE, requires_grad=True)\n",
        "\n",
        "# Export the model to Open Neural Network eXchange (ONNX)\n",
        "model.to_onnx(filename, x, export_params=True)"
      ],
      "metadata": {
        "id": "v45W0Eh1nvRp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}