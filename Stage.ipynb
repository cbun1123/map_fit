{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Stage.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "https://github.com/cbun1123/map_fit/blob/main/Stage.ipynb",
      "authorship_tag": "ABX9TyPeoVU0Hh0uTbvcOlrNiJ7s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cbun1123/map_fit/blob/main/Stage.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!rm -r /content/map_fit\n",
        "!git clone https://github.com/cbun1123/map_fit\n",
        "\n",
        "!unzip /content/map_fit/8bit/X_train_1.zip -d /content/map_fit/8bit/X_train\n",
        "!unzip /content/map_fit/8bit/X_train_2.zip -d /content/map_fit/8bit/X_train\n",
        "!unzip /content/map_fit/8bit/X_train_3.zip -d /content/map_fit/8bit/X_train\n",
        "\n",
        "!unzip /content/map_fit/8bit/X_test_1.zip -d /content/map_fit/8bit/X_test\n",
        "\n",
        "!rm /content/map_fit/*.zip"
      ],
      "metadata": {
        "id": "0mtWihytt32k"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "#!pip install cloud-tpu-client==0.10 torch==1.12.0 https://storage.googleapis.com/tpu-pytorch/wheels/cuda/112/torch_xla-1.12-cp37-cp37m-linux_x86_64.whl --force-reinstall\n",
        "#!pip install git+https://github.com/PytorchLightning/pytorch-lightning.git@master --upgrade\n",
        "!pip install pytorch-lightning #==1.5.10\n",
        "!pip install tensorboardcolab\n",
        "!pip install torchmetrics\n",
        "!pip install \"ray[tune]\"\n",
        "!pip install GPUtil\n",
        "%env PYTHONPATH=.:$PYTHONPATH"
      ],
      "metadata": {
        "id": "PyjF4ET6Ryta"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ow-HQUN3k9SA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "571ea275-08fe-4e48-ca7e-31046cd88d38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Sep  2 11:43:53 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "!nvidia-smi\n",
        "n = 1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Imports\n",
        "import numpy as np\n",
        "import cv2\n",
        "import glob\n",
        "import math\n",
        "import time\n",
        "import os\n",
        "import gc\n",
        "import natsort\n",
        "import logging\n",
        "import copy\n",
        "\n",
        "from IPython.utils import io\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import files\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.onnx\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "import ray\n",
        "from ray import air,tune\n",
        "from ray.tune.integration.pytorch_lightning import TuneReportCallback,TuneReportCheckpointCallback\n",
        "\n",
        "import GPUtil\n",
        "\n",
        "import torchmetrics\n",
        "from torchmetrics.functional import *\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "\n",
        "#import torch_xla\n",
        "#import torch_xla.core.xla_model as xm"
      ],
      "metadata": {
        "id": "Gj6-PAXEtQDT",
        "cellView": "form"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir='/content/lightning_logs'"
      ],
      "metadata": {
        "id": "863-WKKY3pU6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Load dataset\n",
        "#@markdown Loads datasets and creates training and testing dataloaders\n",
        "SIZE = 224\n",
        "\n",
        "# Define circular mask for RGB tensor image\n",
        "lin = np.linspace(-1,1,SIZE)\n",
        "[Xm,Ym] = np.meshgrid(lin,lin)\n",
        "idx = ((Xm**2+Ym**2)<1)\n",
        "idx = np.stack([idx,idx,idx], axis=0)\n",
        "idx_t = torch.from_numpy(idx)\n",
        "\n",
        "# Define custom dataset class inheriting from torch.Dataset\n",
        "class imageDataset(Dataset):\n",
        "    def __init__(self,X,y,Z):\n",
        "        'Initialization'\n",
        "        # Load data\n",
        "        self.X = np.array(X).astype(np.float32)\n",
        "        self.y = np.array(y).astype(np.float32)\n",
        "        self.Z = np.array(Z).astype(np.float32)\n",
        "\n",
        "        # Define dataset size\n",
        "        self.n_samples = self.X.shape[0]\n",
        "\n",
        "        # Define target distribution\n",
        "        mean = torch.tensor([0.5, 0.5, 0.5]).view(3,1,1)\n",
        "        std = torch.tensor([0.5, 0.5, 0.5]).view(3,1,1)\n",
        "\n",
        "        # Define corrected distribution for masked image\n",
        "        fact = torch.div(SIZE**2,idx_t.sum(dim=[1,2])).view(3,1,1)\n",
        "        corr_mean = torch.mul(fact,mean)\n",
        "        corr_std = torch.sqrt(torch.mul(fact,torch.pow(std,2)) - torch.mul(torch.mul(fact,fact-1),torch.pow(mean,2)))\n",
        "\n",
        "        # Define transformations\n",
        "        lambdaMask = lambda T: torch.mul(T,idx_t)\n",
        "        lambdaNorm = lambda T: torch.div(T-T.mean(dim=[1,2]).view(3,1,1),T.std(dim=[1,2]).view(3,1,1))\n",
        "        lambdaScale = lambda T: torch.mul(T,corr_std) + corr_mean\n",
        "\n",
        "        # Define global transformation\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambdaMask),\n",
        "            transforms.Lambda(lambdaNorm),\n",
        "            transforms.Lambda(lambdaScale),\n",
        "            transforms.Lambda(lambdaMask),\n",
        "        ])\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generates one sample of data'\n",
        "        # Select sample\n",
        "        X = self.X[index]\n",
        "\n",
        "        # Rescale sample to original values\n",
        "        #X = (X/255)*(self.Z[index,1]-self.Z[index,0]) + self.Z[index,0]\n",
        "\n",
        "        # Apply transforms\n",
        "        X = self.transform(X)\n",
        "\n",
        "        # Load and format labels\n",
        "        y = self.y[index]\n",
        "        y = torch.from_numpy(y)\n",
        "\n",
        "        # Package sample\n",
        "        sample = X,y\n",
        "        return sample\n",
        "\n",
        "    def __len__(self):\n",
        "        'Dataset length'\n",
        "        return self.n_samples\n",
        "\n",
        "    def getData(self):\n",
        "        'Returns all data labels'\n",
        "\n",
        "        # Load all images\n",
        "        #X = torch.stack([torch.mul(self.transform(self.X[i]),idx_t) for i in range(len(self.y))])\n",
        "\n",
        "        # Load all labels\n",
        "        y = torch.from_numpy(self.y)\n",
        "        return y\n",
        "\n",
        "## Training data\n",
        "train_num = 3000 #@param {type:\"slider\", min:0, max:10000, step:1}\n",
        "# Load training images\n",
        "filenames = glob.glob(\"/content/map_fit/8bit/X_train/*.jpg\")\n",
        "filenames = natsort.natsorted(filenames)\n",
        "X_train = [cv2.imread(img,-1) for img in filenames[0:train_num]] # cv2.imread(img)\n",
        "\n",
        "# Load training labels\n",
        "y_train = np.load('/content/map_fit/8bit/Y_train.npy')[0:train_num]\n",
        "Z_train = np.load('/content/map_fit/8bit/Z_train.npy')[0:train_num]\n",
        "\n",
        "## Testing data\n",
        "test_num = 300 #@param {type:\"slider\", min:0, max:2000, step:1}\n",
        "# Load testing images\n",
        "filenames = glob.glob(\"/content/map_fit/8bit/X_test/*.jpg\")\n",
        "filenames = natsort.natsorted(filenames)\n",
        "X_test = [cv2.imread(img,-1) for img in filenames[0:test_num]]\n",
        "\n",
        "# Load training labels\n",
        "y_test = np.load('/content/map_fit/8bit/Y_test.npy')[0:test_num]\n",
        "Z_test = np.load('/content/map_fit/8bit/Z_test.npy')[0:test_num]\n",
        "\n",
        "# Initialize datasets\n",
        "trainset = imageDataset(X_train,y_train,Z_train)\n",
        "testset = imageDataset(X_test,y_test,Z_test)\n",
        "\n",
        "# Print dataset sizes\n",
        "print(f'Training set : {np.shape(X_train)}')\n",
        "print(f'Testing set : {np.shape(X_test)}')\n",
        "\n",
        "\n",
        "# Garbage collection\n",
        "del X_train\n",
        "del y_train\n",
        "del X_test\n",
        "del y_test\n",
        "del filenames\n",
        "del Xm\n",
        "del Ym\n",
        "del lin\n",
        "del idx\n",
        "gc.collect()"
      ],
      "metadata": {
        "id": "YeaSHISWLPdA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9f11c8-0ba7-48c0-b5d2-af6072183d21",
        "cellView": "form"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set : (3000, 224, 224)\n",
            "Testing set : (300, 224, 224)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Freezing weights:\n",
        "```\n",
        "for param in backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "self.net = backbone\n",
        "```\n",
        "\n",
        "Replacing last layer:\n",
        "```\n",
        "backbone.fc = nn.Linear(in_features=backbone.fc.in_features, out_features=3, bias=True)\n",
        "self.net = backbone\n",
        "```\n",
        "\n",
        "Adding new last layer:\n",
        "```\n",
        "added_layer = nn.Linear(in_features=backbone.fc.out_features, out_features=3, bias=True)\n",
        "self.net = nn.Sequential(backbone,nn.ReLU(inplace=True),added_layer)\n",
        "```"
      ],
      "metadata": {
        "id": "zasYanDzx5Xy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Defining model and non-tuned hyperparameters\n",
        "# Define model\n",
        "model_name = \"squeezenet1_1\" #@param {type:\"string\"}\n",
        "\n",
        "# Define hyperparameters\n",
        "BATCH_SIZE = 256 #@param {type:\"integer\"} # TPU has very little memory, 64 max\n",
        "\n",
        "#learning_rate = 0.0015\n",
        "#weight_decay = 1e-6\n",
        "#dropout_rate = 0.5\n",
        "#swa_lrs = 1e-6\n",
        "\n",
        "betas = [0.9,0.999]\n",
        "eps = 1e-8\n",
        "\n",
        "#@markdown Learning rate scheduler period\n",
        "step_size = 5 #@param {type:\"integer\"}\n",
        "#@markdown Learning rate scheduler factor\n",
        "gamma = 0.8 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "# Define pyTorch-Lightning model class inheriting from LightningModule class\n",
        "class LitModel(pl.LightningModule):\n",
        "    def __init__(self,config,TrainLoader,TestLoader):\n",
        "        'Initialize module'\n",
        "        # Inherit initialization from LightningModule class\n",
        "        super().__init__()\n",
        "        # Define internal hyperparameters for tuning\n",
        "        self.batch_size = BATCH_SIZE\n",
        "        self.lr = config[\"learning_rate\"]\n",
        "        self.wd = config[\"weight_decay\"]\n",
        "        self.p = config[\"dropout_rate\"]\n",
        "\n",
        "        self.TrainLoader = copy.deepcopy(TrainLoader)\n",
        "        self.TestLoader = copy.deepcopy(TestLoader)\n",
        "\n",
        "        # Initialize a pretrained network\n",
        "        backbone = torch.hub.load('pytorch/vision:v0.10.0', model_name, pretrained=True)\n",
        "        #backbone = torchvision.models.shufflenet_v2_x1_0(pretrained=True)\n",
        "\n",
        "        # Custom dropout rate (default 0.5)\n",
        "        backbone.classifier[0] = nn.Dropout(p=self.p, inplace=False)\n",
        "\n",
        "        # Add fully-connected last layer for 3 parameter regression\n",
        "        added_layer = nn.Linear(in_features=1000, out_features=3, bias=True)\n",
        "        self.net = nn.Sequential(backbone,added_layer)\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        'Training optimizers definition'\n",
        "        # Backpropagation optimize\n",
        "        optimizer = torch.optim.AdamW(self.parameters(), lr=self.lr, betas=betas, eps=eps, weight_decay=self.wd)\n",
        "        #optimizer = torch.optim.RMSprop(self.parameters(), lr=self.lr, alpha=0.86, eps=eps, weight_decay=self.wd, momentum=0.9)\n",
        "\n",
        "        # Learning rate scheduler\n",
        "        lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer,step_size=step_size,gamma=gamma)\n",
        "        return [optimizer], [lr_scheduler]\n",
        "\n",
        "    def forward(self,x):\n",
        "        'Forward function'\n",
        "        return self.net(x)\n",
        "\n",
        "    def train_dataloader(self):\n",
        "        'Internal training dataloader'\n",
        "        return self.TrainLoader\n",
        "\n",
        "    def val_dataloader(self):\n",
        "        'Internal validation dataloader'\n",
        "        return self.TestLoader\n",
        "\n",
        "    def test_dataloader(self):\n",
        "        'Internal testing dataloader'\n",
        "        return self.TestLoader\n",
        "\n",
        "    def predict_dataloader(self):\n",
        "        'Internal prediction dataloader'\n",
        "        return self.TestLoader\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        'Training loop step'\n",
        "        # Get data from batch\n",
        "        input, labels = batch\n",
        "        # Compute predictions\n",
        "        output = self.net(input)\n",
        "        # Compute loss\n",
        "        loss = F.mse_loss(output,labels) # mean_squared_log_error(output,labels) # F.mse_loss(output,labels)\n",
        "        # Logging to TensorBoard\n",
        "        self.log(\"train_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        'Validation loop step'\n",
        "        # Get data from batch\n",
        "        input, labels = batch\n",
        "        # Compute predictions\n",
        "        output = self.net(input)\n",
        "        # Compute loss\n",
        "        loss = F.mse_loss(output,labels)\n",
        "        # Logging to TensorBoard\n",
        "        self.log(\"val_loss\", loss, prog_bar=True)\n",
        "        return loss\n",
        "\n",
        "    def validation_epoch_end(self, outputs):\n",
        "        avg_loss = torch.stack(outputs).mean().item()\n",
        "        self.log(\"ptl/val_loss\", avg_loss)\n",
        "        self.log(\"epoch\", np.float32(self.current_epoch))\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        'Testing loop step'\n",
        "        # Get data from batch\n",
        "        input, labels = batch\n",
        "        # Compute predictions\n",
        "        output = self.net(input)\n",
        "        # Compute loss\n",
        "        loss = torch.std(labels-output, dim=0).mean()\n",
        "        # Logging to TensorBoard\n",
        "        self.log(\"test_loss\", loss)\n",
        "        return loss\n",
        "\n",
        "    def predict_step(self, batch, batch_idx):\n",
        "        'Prediction loop step'\n",
        "        # Get data from batch\n",
        "        input, labels = batch\n",
        "        # Compute predictions\n",
        "        return self.net(input)"
      ],
      "metadata": {
        "id": "Vl6yhwY9coxM"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Raytune hyperparameter tuning\n",
        "\n",
        "# Garbage collection\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "n_trials = 10 #@param {type:\"integer\"}\n",
        "max_epochs = 1 #@param {type:\"integer\"}\n",
        "#@markdown Patience\n",
        "grace_period = 1 #@param {type:\"integer\"}\n",
        "num_epochs = 1 #@param {type:\"integer\"}\n",
        "val_check_interval = 0.5 #@param {type:\"slider\", min:0, max:1, step:0.01}\n",
        "\n",
        "TrainLoader = DataLoader(dataset=trainset, batch_size=BATCH_SIZE)\n",
        "TestLoader = DataLoader(dataset=testset, batch_size=BATCH_SIZE)\n",
        "\n",
        "def train_network(config,TrainLoader,TestLoader):\n",
        "    # Garbage collection\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "    logger = pl.loggers.TensorBoardLogger(save_dir=os.getcwd(), name=\"\", version=\".\"),\n",
        "\n",
        "\n",
        "    metrics = {\"val_loss\": \"ptl/val_loss\", \"epoch\": \"epoch\"}\n",
        "    tuning_callback = TuneReportCheckpointCallback(\n",
        "                metrics=metrics,\n",
        "                filename=\"checkpoint\",\n",
        "                on=\"validation_end\")\n",
        "\n",
        "    stagnate_callback = pl.callbacks.EarlyStopping(\n",
        "        monitor=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        check_finite=True,\n",
        "        patience=np.ceil(num_epochs/val_check_interval)\n",
        "        )\n",
        "    \n",
        "    swa_callback = pl.callbacks.StochasticWeightAveraging(config[\"swa_lrs\"])\n",
        "    \n",
        "    \n",
        "    trainer = pl.Trainer(\n",
        "        accelerator=\"auto\",             # CPU, GPU or TPU\n",
        "        logger=logger,\n",
        "        val_check_interval=val_check_interval,\n",
        "        max_epochs=max_epochs,         # -1 for Infinite\n",
        "        enable_checkpointing=True,     # True or False\n",
        "        callbacks=[tuning_callback, swa_callback],\n",
        "        gradient_clip_val=0.25,\n",
        "        log_every_n_steps=1,\n",
        "        enable_progress_bar=True,\n",
        "        enable_model_summary=False,\n",
        "        detect_anomaly=True\n",
        "        )  \n",
        "\n",
        "    model = LitModel(config,TrainLoader,TestLoader)\n",
        "    #tune.utils.wait_for_gpu()\n",
        "    trainer.fit(model=model)\n",
        "\n",
        "    # Garbage collection\n",
        "    torch.cuda.empty_cache()\n",
        "    gc.collect()\n",
        "\n",
        "config = {\n",
        " \"learning_rate\": tune.loguniform(1e-6, 1e-2),\n",
        " \"weight_decay\": tune.loguniform(1e-8, 1e-2),\n",
        " \"dropout_rate\": tune.uniform(0.1, 0.6),\n",
        " \"swa_lrs\": tune.loguniform(1e-7,1e-2)\n",
        "}\n",
        "\n",
        "scheduler = tune.schedulers.AsyncHyperBandScheduler(\n",
        "    max_t=np.ceil(max_epochs/val_check_interval),\n",
        "    grace_period=np.ceil(grace_period/val_check_interval),\n",
        "    reduction_factor=4)\n",
        "\n",
        "trainable = tune.with_parameters(\n",
        "    train_network,\n",
        "    TrainLoader=TrainLoader,\n",
        "    TestLoader=TestLoader) #, args\n",
        "\n",
        "reporter = tune.CLIReporter(\n",
        "        parameter_columns=[\"learning_rate\", \"weight_decay\", \"dropout_rate\", \"swa_lrs\"],\n",
        "        metric_columns=[\"val_loss\",\"epoch\"])\n",
        "\n",
        "tuner = tune.Tuner(\n",
        "    tune.with_resources(\n",
        "        trainable,\n",
        "        resources={\"cpu\": 2, \"gpu\": 1},\n",
        "    ),\n",
        "    tune_config=tune.TuneConfig(\n",
        "        metric=\"val_loss\",\n",
        "        mode=\"min\",\n",
        "        scheduler=scheduler,\n",
        "        num_samples=n_trials,\n",
        "    ),\n",
        "    run_config=air.RunConfig(\n",
        "        name=\"train_network\",\n",
        "        progress_reporter=reporter,\n",
        "    ),\n",
        "    param_space=config,\n",
        ")\n",
        "\n",
        "results = tuner.fit()\n",
        "\n",
        "print(\"Best hyperparameters found were: \", results.get_best_result().config)"
      ],
      "metadata": {
        "id": "Dye8BmrJ0s-b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "acc940e0-c5a5-4335-8867-41533d6fa04b"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TuneError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31m_InactiveRpcError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/experiment/experiment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, run, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, _experiment_checkpoint_dir, sync_config, trial_name_creator, trial_dirname_creator, log_to_file, checkpoint_freq, checkpoint_at_end, keep_checkpoints_num, checkpoint_score_attr, export_formats, max_failures, restore)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_identifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/experiment/experiment.py\u001b[0m in \u001b[0;36mregister_if_needed\u001b[0;34m(cls, run_object)\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m             \u001b[0mregister_trainable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPicklingError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/registry.py\u001b[0m in \u001b[0;36mregister_trainable\u001b[0;34m(name, trainable, warn)\u001b[0m\n\u001b[1;32m    100\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Second argument must be convertable to Trainable\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m     \u001b[0m_global_registry\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAINABLE_CLASS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/registry.py\u001b[0m in \u001b[0;36mregister\u001b[0;34m(self, category, key, value)\u001b[0m\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_internal_kv_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/registry.py\u001b[0m in \u001b[0;36mflush_values\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    211\u001b[0m             _internal_kv_put(\n\u001b[0;32m--> 212\u001b[0;31m                 \u001b[0m_make_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_prefix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcategory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    104\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/experimental/internal_kv.py\u001b[0m in \u001b[0;36m_internal_kv_put\u001b[0;34m(key, value, overwrite, namespace)\u001b[0m\n\u001b[1;32m     93\u001b[0m     )\n\u001b[0;32m---> 94\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mglobal_gcs_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minternal_kv_put\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/_private/gcs_utils.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/_private/gcs_utils.py\u001b[0m in \u001b[0;36minternal_kv_put\u001b[0;34m(self, key, value, overwrite, namespace, timeout)\u001b[0m\n\u001b[1;32m    295\u001b[0m         )\n\u001b[0;32m--> 296\u001b[0;31m         \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kv_stub\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInternalKVPut\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mGcsCode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOK\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, timeout, metadata, credentials, wait_for_ready, compression)\u001b[0m\n\u001b[1;32m    945\u001b[0m                                       wait_for_ready, compression)\n\u001b[0;32m--> 946\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_end_unary_response_blocking\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    947\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/grpc/_channel.py\u001b[0m in \u001b[0;36m_end_unary_response_blocking\u001b[0;34m(state, call, with_call, deadline)\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 849\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0m_InactiveRpcError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    850\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31m_InactiveRpcError\u001b[0m: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Sent message larger than max (662555068 vs. 536870912)\"\n\tdebug_error_string = \"{\"created\":\"@1662122035.163910271\",\"description\":\"Sent message larger than max (662555068 vs. 536870912)\",\"file\":\"src/core/ext/filters/message_size/message_size_filter.cc\",\"file_line\":264,\"grpc_status\":8}\"\n>",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/tuner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_local_tuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    235\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/impl/tuner_internal.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    282\u001b[0m             \u001b[0mparam_space\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_param_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m             \u001b[0manalysis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_space\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    284\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/impl/tuner_internal.py\u001b[0m in \u001b[0;36m_fit_internal\u001b[0;34m(self, trainable, param_space)\u001b[0m\n\u001b[1;32m    380\u001b[0m         analysis = run(\n\u001b[0;32m--> 381\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/tune.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(run_or_experiment, name, metric, mode, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, search_alg, scheduler, keep_checkpoints_num, checkpoint_score_attr, checkpoint_freq, checkpoint_at_end, verbose, progress_reporter, log_to_file, trial_name_creator, trial_dirname_creator, sync_config, export_formats, max_failures, fail_fast, restore, server_port, resume, reuse_actors, trial_executor, raise_on_failed_trial, callbacks, max_concurrent_trials, _experiment_checkpoint_dir, _remote)\u001b[0m\n\u001b[1;32m    539\u001b[0m                 \u001b[0mmax_failures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_failures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m                 \u001b[0mrestore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrestore\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/experiment/experiment.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, run, stop, time_budget_s, config, resources_per_trial, num_samples, local_dir, _experiment_checkpoint_dir, sync_config, trial_name_creator, trial_dirname_creator, log_to_file, checkpoint_freq, checkpoint_at_end, keep_checkpoints_num, checkpoint_score_attr, export_formats, max_failures, restore)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 raise TuneError(\n\u001b[0;32m--> 167\u001b[0;31m                     \u001b[0;34mf\"The Trainable/training function is too large for grpc resource \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m                     \u001b[0;34mf\"limit. Check that its definition is not implicitly capturing a \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTuneError\u001b[0m: The Trainable/training function is too large for grpc resource limit. Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use tune.with_parameters() to put large objects in the Ray object store. \nOriginal exception: Traceback (most recent call last):\n  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/experiment/experiment.py\", line 163, in __init__\n    self._run_identifier = Experiment.register_if_needed(run)\n  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/experiment/experiment.py\", line 356, in register_if_needed\n    register_trainable(name, run_object)\n  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/registry.py\", line 101, in register_trainable\n    _global_registry.register(TRAINABLE_CLASS, name, trainable)\n  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/registry.py\", line 189, in register\n    self.flush_values()\n  File \"/usr/local/lib/python3.7/dist-packages/ray/tune/registry.py\", line 212, in flush_values\n    _make_key(self._prefix, category, key), value, overwrite=True\n  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/client_mode_hook.py\", line 105, in wrapper\n    return func(*args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ray/experimental/internal_kv.py\", line 94, in _internal_kv_put\n    return global_gcs_client.internal_kv_put(key, value, overwrite, namespace) == 0\n  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/gcs_utils.py\", line 177, in wrapper\n    return f(self, *args, **kwargs)\n  File \"/usr/local/lib/python3.7/dist-packages/ray/_private/gcs_utils.py\", line 296, in internal_kv_put\n    reply = self._kv_stub.InternalKVPut(req, timeout=timeout)\n  File \"/usr/local/lib/python3.7/dist-packages/grpc/_channel.py\", line 946, in __call__\n    return _end_unary_response_blocking(state, call, False, None)\n  File \"/usr/local/lib/python3.7/dist-packages/grpc/_channel.py\", line 849, in _end_unary_response_blocking\n    raise _InactiveRpcError(state)\ngrpc._channel._InactiveRpcError: <_InactiveRpcError of RPC that terminated with:\n\tstatus = StatusCode.RESOURCE_EXHAUSTED\n\tdetails = \"Sent message larger than max (662555068 vs. 536870912)\"\n\tdebug_error_string = \"{\"created\":\"@1662122035.163910271\",\"description\":\"Sent message larger than max (662555068 vs. 536870912)\",\"file\":\"src/core/ext/filters/message_size/message_size_filter.cc\",\"file_line\":264,\"grpc_status\":8}\"\n>\n",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mTuneError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-39-4c0d1e735d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    101\u001b[0m )\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Best hyperparameters found were: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_best_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/ray/tune/tuner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    238\u001b[0m                     \u001b[0;34mf'Please use tuner = Tuner.restore(\"'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m                     \u001b[0;34mf'{self._local_tuner.get_experiment_checkpoint_dir()}\") to resume.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m                 ) from e\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m             experiment_checkpoint_dir = ray.get(\n",
            "\u001b[0;31mTuneError\u001b[0m: Tune run failed. Please use tuner = Tuner.restore(\"/root/ray_results/train_network\") to resume."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_trial = results.best_trial  # Get best trial\n",
        "best_config = results.best_config  # Get best trial's hyperparameters\n",
        "best_checkpoint = results.best_checkpoint  # Get best trial's best checkpoint\n",
        "best_result = results.best_result  # Get best trial's last results"
      ],
      "metadata": {
        "id": "9xCh-4FhMoZz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Training\n",
        "# Garbage collection\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Model initialization, possibly by checkpoint\n",
        "#@markdown Leave empty if no checkpoint\n",
        "ckpt_name = \"\" #@param {type:\"string\"}\n",
        "if ckpt_name == \"\":\n",
        "    model = LitModel()\n",
        "else:\n",
        "    model = LitModel().load_from_checkpoint(\"/content/checkpoints/\" + ckpt_name + \".ckpt\")\n",
        "\n",
        "\n",
        "# Define TensorBoard logger\n",
        "logger = pl.loggers.TensorBoardLogger(save_dir=os.getcwd(), version=n, name=\"lightning_logs\")\n",
        "n += 1\n",
        "\n",
        "# Define training callbacks\n",
        "checkpoint_callback = pl.callbacks.ModelCheckpoint(dirpath=\"/content/checkpoints\",\n",
        "                                      save_last=True,\n",
        "                                      save_top_k=1,\n",
        "                                      monitor=\"val_loss\",\n",
        "                                      mode=\"min\",\n",
        "                                      filename=model_name+\"-{epoch:02d}-{val_loss:.5f}\"\n",
        "                                      )\n",
        "stagnate_callback = pl.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
        "                                               mode=\"min\",\n",
        "                                               check_finite=True,\n",
        "                                               patience=np.ceil(num_epochs/val_check_interval)\n",
        "                                               )\n",
        "swa_callback = pl.callbacks.StochasticWeightAveraging(swa_lrs=swa_lrs)\n",
        "\n",
        "# Defining trainer\n",
        "trainer = pl.Trainer(accelerator=\"gpu\",             # CPU, GPU or TPU\n",
        "                     val_check_interval=val_check_interval,\n",
        "                     auto_lr_find=False,            # True or False   \n",
        "                     auto_scale_batch_size=None,    # None or \"binsearch\"\n",
        "                     deterministic=False,           # True or False\n",
        "                     fast_dev_run=False,            # True or False or Epoch count\n",
        "                     logger=logger,                 # logger or False\n",
        "                     max_epochs=1000,               # -1 for Infinite\n",
        "                     precision=32,                  # Default 32\n",
        "                     profiler=None,                 # None, \"simple\" or \"advanced\"\n",
        "                     enable_checkpointing=True,     # True or False\n",
        "                     callbacks=[checkpoint_callback, stagnate_callback, swa_callback],\n",
        "                     gradient_clip_val=0.25,\n",
        "                     log_every_n_steps=1\n",
        "                     #, detect_anomaly=True #, overfit_batches=1\n",
        "                     )                  \n",
        "\n",
        "# Autotune hyperparameters\n",
        "trainer.tune(model=model)\n",
        "\n",
        "# Training\n",
        "trainer.fit(model=model)"
      ],
      "metadata": {
        "id": "a2eqAEcNKafw",
        "cellView": "code"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Evaluate test set\n",
        "# Garbage collection\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Load best checkpoint and get testing loss\n",
        "#t_loss = trainer.test()[0].get('test_loss')\n",
        "\n",
        "# Get test labels\n",
        "y_test = testset.getData()\n",
        "\n",
        "# Load best checkpoint and get test predictions\n",
        "y_pred = torch.vstack(trainer.predict())"
      ],
      "metadata": {
        "id": "fGt8UkbtXCI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Response distribution\n",
        "# Garbage collection\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Print mean relative errors\n",
        "#print(torch.abs(torch.div(y_pred-y_test,y_test)).mean().item())\n",
        "##print(torch.abs(torch.div(y_pred-y_test,y_pred)).mean().item())\n",
        "\n",
        "# Define RMS histogram binning\n",
        "nb = 20\n",
        "bins1 = np.arange(0, max(torch.max(y_test[:,0]), torch.max(y_pred[:,0])), 1/(2*nb))\n",
        "bins2 = np.arange(0, max(torch.max(y_test[:,1]), torch.max(y_pred[:,1])), 1/(nb/2))\n",
        "bins3 = np.arange(0, max(torch.max(y_test[:,2]), torch.max(y_pred[:,2])), 1/(2*nb))\n",
        "\n",
        "# Plot RMS distributions\n",
        "plt.subplot(1,3,1)\n",
        "plt.hist(y_test[:,0], bins=bins1, color='white', edgecolor='black')\n",
        "plt.hist(y_pred[:,0], bins=bins1, color='blue', alpha=0.6)\n",
        "plt.title(\"Dist RMS MHF\")\n",
        "plt.subplot(1,3,2)\n",
        "plt.hist(y_test[:,1], bins=bins2, color='white', edgecolor='black')\n",
        "plt.hist(y_pred[:,1], bins=bins2, color='blue', alpha=0.6)\n",
        "plt.title(\"Dist RMS BdR\")\n",
        "plt.subplot(1,3,3)\n",
        "plt.hist(y_test[:,2], bins=bins3, color='white', edgecolor='black')\n",
        "plt.hist(y_pred[:,2], bins=bins3, color='blue', alpha=0.6)\n",
        "plt.title(\"Dist RMS MFcirc\")\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Define error distributions\n",
        "D_mhf = y_pred[:,0]-y_test[:,0] #torch.div(y_pred[:,0]-y_test[:,0],y_pred[:,0])\n",
        "D_bdr = y_pred[:,1]-y_test[:,1] #torch.div(y_pred[:,1]-y_test[:,1],y_pred[:,1])\n",
        "D_mfcirc = y_pred[:,2]-y_test[:,2] #torch.div(y_pred[:,2]-y_test[:,2],y_pred[:,2])\n",
        "\n",
        "# Define error histogram binning\n",
        "nb = 20\n",
        "bins4 = np.arange(-1, 1, 1/nb)\n",
        "bins5 = np.arange(-1, 1, 1/nb)\n",
        "bins6 = np.arange(-1, 1, 1/nb)\n",
        "\n",
        "# Plot error distributions\n",
        "plt.subplot(1,3,1)\n",
        "plt.hist(D_mhf, bins=bins4, color='blue', edgecolor='black')\n",
        "plt.title(\"Erreurs relatives MHF\")\n",
        "plt.subplot(1,3,2)\n",
        "plt.hist(D_bdr, bins=bins5, color='blue', edgecolor='black')\n",
        "plt.title(\"Erreurs relatives BdR\")\n",
        "plt.subplot(1,3,3)\n",
        "plt.hist(D_mfcirc, bins=bins6, color='blue', edgecolor='black')\n",
        "plt.title(\"Erreurs relatives MFcirc\")\n",
        "plt.show()\n",
        "\n",
        "# Print error std\n",
        "std_mhf = torch.std(D_mhf).item()\n",
        "std_bdr = torch.std(D_bdr).item()\n",
        "std_mfcirc = torch.std(D_mfcirc).item()\n",
        "print(f'Standard deviation of MHF errors :    {std_mhf:.3f}')\n",
        "print(f'Standard deviation of BdR errors :    {std_bdr:.3f}')\n",
        "print(f'Standard deviation of MFcirc errors : {std_mfcirc:.3f}')"
      ],
      "metadata": {
        "id": "pFQ-UsQF80CM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Single example\n",
        "# Load image and define parameters\n",
        "test_img = cv2.imread(\"/content/map_fit/8bit/-137.319_158.003_37.932_20_30.jpg\",-1)\n",
        "Z = [-137.319,158.003]\n",
        "RMS = 37.932\n",
        "E_RMS = [10,20,30]\n",
        "\n",
        "# Show test image\n",
        "cv2_imshow(test_img)\n",
        "\n",
        "# Normalize image\n",
        "X = np.array(test_img).astype(np.float32)\n",
        "X = (X/255)*(Z[1]-Z[0])+Z[0]\n",
        "X = X/RMS\n",
        "\n",
        "# Define target distribution\n",
        "mean = torch.tensor([0.5, 0.5, 0.5]).view(3,1,1)\n",
        "std = torch.tensor([0.5, 0.5, 0.5]).view(3,1,1)\n",
        "\n",
        "# Define corrected distribution for masked image\n",
        "fact = torch.div(SIZE**2,idx_t.sum(dim=[1,2])).view(3,1,1)\n",
        "corr_mean = torch.mul(fact,mean)\n",
        "corr_std = torch.sqrt(torch.mul(fact,torch.pow(std,2)) - torch.mul(torch.mul(fact,fact-1),torch.pow(mean,2)))\n",
        "\n",
        "# Define transformations\n",
        "lambdaMask = lambda T: torch.mul(T,idx_t)\n",
        "lambdaNorm = lambda T: torch.div(T-T.mean(dim=[1,2]).view(3,1,1),T.std(dim=[1,2]).view(3,1,1))\n",
        "lambdaScale = lambda T: torch.mul(T,corr_std) + corr_mean\n",
        "\n",
        "# Compute transformed image\n",
        "X = transforms.Compose([\n",
        "            transforms.ToPILImage(),\n",
        "            #transforms.Grayscale(num_output_channels=3),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Lambda(lambdaMask),\n",
        "            transforms.Lambda(lambdaNorm),\n",
        "            transforms.Lambda(lambdaScale),\n",
        "            transforms.Lambda(lambdaMask),\n",
        "            ])(X)\n",
        "\n",
        "# Add dummy batch dimension\n",
        "X = X[None,:,:,:]\n",
        "\n",
        "# Compute prediction\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    y = model(X)\n",
        "\n",
        "# Print results\n",
        "print(f' Expected RMS:    {E_RMS[0]:.3f},    {E_RMS[1]:.3f},    {E_RMS[2]:.3f}')\n",
        "print(f'Predicted RMS:    {RMS*y[0,0].item():.3f},    {RMS*y[0,1].item():.3f},    {RMS*y[0,2].item():.3f}')\n",
        "print(f' Error at std:  +-{std_mhf*RMS:.3f},  +-{std_bdr*RMS:.3f},  +-{std_mfcirc*RMS:.3f}')"
      ],
      "metadata": {
        "id": "aBbcZe7prq22",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title #Export to .onnx\n",
        "#@markdown Errors on this block are mostly fixed by restarting it\n",
        "# Target filename\n",
        "filename = f'C:/Users/maele/Desktop/map_fit-main/Export/{model_name}_{std_mhf:.3f}_{std_bdr:.3f}_{std_mfcirc:.3f}.onnx' # drive/MyDrive/ \n",
        "\n",
        "# Example input\n",
        "x = torch.randn(1, 3, SIZE, SIZE, requires_grad=True)\n",
        "\n",
        "# Export the model to Open Neural Network eXchange (ONNX)\n",
        "model.to_onnx(filename, x, export_params=True)"
      ],
      "metadata": {
        "id": "v45W0Eh1nvRp",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}